{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Models/VCTK20\n",
      ".2\n",
      ".cuda\n",
      ".150\n",
      ".5\n",
      ".\n",
      ".False\n",
      ".True\n",
      ".Data/train_list.txt\n",
      ".Data/val_list.txt\n",
      ".Utils/JDC/bst.t7\n",
      ".Utils/ASR/config.yml\n",
      ".Utils/ASR/epoch_00100.pth\n",
      ".24000\n",
      ".2048\n",
      ".1200\n",
      ".300\n",
      ".64\n",
      ".64\n",
      ".16\n",
      ".20\n",
      ".512\n",
      ".4\n",
      ".0\n",
      ".256\n",
      ".1.0\n",
      ".5.0\n",
      ".1.0\n",
      ".1.0\n",
      ".10.0\n",
      ".5.0\n",
      ".0.1\n",
      ".2.0\n",
      ".0.5\n",
      ".0.5\n",
      ".1.0\n",
      ".0.1\n",
      ".10.0\n",
      ".50\n",
      ".30\n",
      ".0.0001\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "def process_yaml(data):\n",
    "    prefix=\"\"\n",
    "    results = []\n",
    "    key_back = \"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            new_prefix = f\"{prefix}.{key}\" if prefix else key\n",
    "            key_back = key\n",
    "            results.extend(process_yaml(value, new_prefix))\n",
    "    elif isinstance(data, list):\n",
    "        for index, item in enumerate(data):\n",
    "            new_prefix = f\"{prefix}[{index}]\"\n",
    "            results.extend(process_yaml(item, new_prefix))\n",
    "    else:\n",
    "        results.append(f\"{prefix}.{data}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def read_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    return process_yaml(data)\n",
    "\n",
    "config_file = r\"C:\\Users\\Neesty\\PycharmProjects\\ml_sim_kc\\intern\\yaml_config\\example.yaml\"\n",
    "processed_data = read_yaml_file(config_file)\n",
    "\n",
    "for line in processed_data:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Models/VCTK20\n",
      ".2\n",
      ".cuda\n",
      ".150\n",
      ".5\n",
      ".\n",
      ".False\n",
      ".True\n",
      ".Data/train_list.txt\n",
      ".Data/val_list.txt\n",
      ".Utils/JDC/bst.t7\n",
      ".Utils/ASR/config.yml\n",
      ".Utils/ASR/epoch_00100.pth\n",
      ".24000\n",
      ".2048\n",
      ".1200\n",
      ".300\n",
      ".64\n",
      ".64\n",
      ".16\n",
      ".20\n",
      ".512\n",
      ".4\n",
      ".0\n",
      ".256\n",
      ".1.0\n",
      ".5.0\n",
      ".1.0\n",
      ".1.0\n",
      ".10.0\n",
      ".5.0\n",
      ".0.1\n",
      ".2.0\n",
      ".0.5\n",
      ".0.5\n",
      ".1.0\n",
      ".0.1\n",
      ".10.0\n",
      ".50\n",
      ".30\n",
      ".0.0001\n"
     ]
    }
   ],
   "source": [
    "class YAMLProcessor:\n",
    "    def __init__(self, prefix=\"\"):\n",
    "        self.prefix = prefix\n",
    "        self.results = []\n",
    "\n",
    "    def process_yaml(self, data):\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                self.process_yaml(value)\n",
    "        elif isinstance(data, list):\n",
    "            for item in data:\n",
    "                self.process_yaml(item)\n",
    "        else:\n",
    "            self.results.append(f\"{self.prefix}.{data}\")\n",
    "\n",
    "    def read_yaml_file(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "        self.process_yaml(data)\n",
    "        return self.results\n",
    "\n",
    "config_file = r\"C:\\Users\\Neesty\\PycharmProjects\\ml_sim_kc\\intern\\yaml_config\\example.yaml\"\n",
    "processor = YAMLProcessor()\n",
    "processed_data = processor.read_yaml_file(config_file)\n",
    "\n",
    "for line in processed_data:\n",
    "    print(line)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Models/VCTK20\n",
      ".2\n",
      ".cuda\n",
      ".150\n",
      ".5\n",
      ".\n",
      ".False\n",
      ".True\n",
      ".Data/train_list.txt\n",
      ".Data/val_list.txt\n",
      ".Utils/JDC/bst.t7\n",
      ".Utils/ASR/config.yml\n",
      ".Utils/ASR/epoch_00100.pth\n",
      ".24000\n",
      ".2048\n",
      ".1200\n",
      ".300\n",
      ".64\n",
      ".64\n",
      ".16\n",
      ".20\n",
      ".512\n",
      ".4\n",
      ".0\n",
      ".256\n",
      ".1.0\n",
      ".5.0\n",
      ".1.0\n",
      ".1.0\n",
      ".10.0\n",
      ".5.0\n",
      ".0.1\n",
      ".2.0\n",
      ".0.5\n",
      ".0.5\n",
      ".1.0\n",
      ".0.1\n",
      ".10.0\n",
      ".50\n",
      ".30\n",
      ".0.0001\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "class YAMLProcessor:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        self.prefix = \"\"\n",
    "\n",
    "    def process_yaml(self, data):\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                new_prefix = f\"{self.prefix}.{key}\" if self.prefix else key\n",
    "                self.process_yaml(value)\n",
    "        elif isinstance(data, list):\n",
    "            for idx, item in enumerate(data):\n",
    "                new_prefix = f\"{self.prefix}[{idx}]\"\n",
    "                self.process_yaml(item)\n",
    "        else:\n",
    "            self.results.append(f\"{self.prefix}.{data}\")\n",
    "\n",
    "    def read_yaml_file(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "        self.process_yaml(data)\n",
    "        return self.results\n",
    "\n",
    "config_file = r\"C:\\Users\\Neesty\\PycharmProjects\\ml_sim_kc\\intern\\yaml_config\\example.yaml\"\n",
    "processor = YAMLProcessor()\n",
    "processed_data = processor.read_yaml_file(config_file)\n",
    "\n",
    "for line in processed_data:\n",
    "    print(line)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir.Models/VCTK20\n",
      "save_freq.2\n",
      "device.cuda\n",
      "epochs.150\n",
      "batch_size.5\n",
      "pretrained_model.\n",
      "load_only_params.False\n",
      "fp16_run.True\n",
      "train_data.Data/train_list.txt\n",
      "val_data.Data/val_list.txt\n",
      "F0_path.Utils/JDC/bst.t7\n",
      "ASR_config.Utils/ASR/config.yml\n",
      "ASR_path.Utils/ASR/epoch_00100.pth\n",
      "preprocess_params.sr.24000\n",
      "preprocess_params.spect_params.n_fft.2048\n",
      "preprocess_params.spect_params.win_length.1200\n",
      "preprocess_params.spect_params.hop_length.300\n",
      "model_params.dim_in.64\n",
      "model_params.style_dim.64\n",
      "model_params.latent_dim.16\n",
      "model_params.num_domains.20\n",
      "model_params.max_conv_dim.512\n",
      "model_params.n_repeat.4\n",
      "model_params.w_hpf.0\n",
      "model_params.F0_channel.256\n",
      "loss_params.g_loss.lambda_sty.1.0\n",
      "loss_params.g_loss.lambda_cyc.5.0\n",
      "loss_params.g_loss.lambda_ds.1.0\n",
      "loss_params.g_loss.lambda_norm.1.0\n",
      "loss_params.g_loss.lambda_asr.10.0\n",
      "loss_params.g_loss.lambda_f0.5.0\n",
      "loss_params.g_loss.lambda_f0_sty.0.1\n",
      "loss_params.g_loss.lambda_adv.2.0\n",
      "loss_params.g_loss.lambda_adv_cls.0.5\n",
      "loss_params.g_loss.norm_bias.0.5\n",
      "loss_params.d_loss.lambda_reg.1.0\n",
      "loss_params.d_loss.lambda_adv_cls.0.1\n",
      "loss_params.d_loss.lambda_con_reg.10.0\n",
      "loss_params.adv_cls_epoch.50\n",
      "loss_params.con_reg_epoch.30\n",
      "optimizer_params.lr.0.0001\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "class YAMLProcessor:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "\n",
    "    def process_yaml(self, data, prefix=\"\"):\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items():\n",
    "                new_prefix = f\"{prefix}.{key}\" if prefix else key\n",
    "                self.process_yaml(value, new_prefix)\n",
    "        elif isinstance(data, list):\n",
    "            for idx, item in enumerate(data):\n",
    "                new_prefix = f\"{prefix}[{idx}]\"\n",
    "                self.process_yaml(item, new_prefix)\n",
    "        else:\n",
    "            self.results.append(f\"{prefix}.{data}\")\n",
    "\n",
    "    def read_yaml_file(self, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "        self.process_yaml(data)\n",
    "        return self.results\n",
    "\n",
    "config_file = r\"C:\\Users\\Neesty\\PycharmProjects\\ml_sim_kc\\intern\\yaml_config\\example.yaml\"\n",
    "processor = YAMLProcessor()\n",
    "processed_data = processor.read_yaml_file(config_file)\n",
    "\n",
    "for line in processed_data:\n",
    "    print(line)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir.Models/VCTK20\n",
      "save_freq.2\n",
      "device.cuda\n",
      "epochs.150\n",
      "batch_size.5\n",
      "pretrained_model.\n",
      "load_only_params.False\n",
      "fp16_run.True\n",
      "train_data.Data/train_list.txt\n",
      "val_data.Data/val_list.txt\n",
      "F0_path.Utils/JDC/bst.t7\n",
      "ASR_config.Utils/ASR/config.yml\n",
      "ASR_path.Utils/ASR/epoch_00100.pth\n",
      "preprocess_params.sr.24000\n",
      "preprocess_params.spect_params.n_fft.2048\n",
      "preprocess_params.spect_params.win_length.1200\n",
      "preprocess_params.spect_params.hop_length.300\n",
      "model_params.dim_in.64\n",
      "model_params.style_dim.64\n",
      "model_params.latent_dim.16\n",
      "model_params.num_domains.20\n",
      "model_params.max_conv_dim.512\n",
      "model_params.n_repeat.4\n",
      "model_params.w_hpf.0\n",
      "model_params.F0_channel.256\n",
      "loss_params.g_loss.lambda_sty.1.0\n",
      "loss_params.g_loss.lambda_cyc.5.0\n",
      "loss_params.g_loss.lambda_ds.1.0\n",
      "loss_params.g_loss.lambda_norm.1.0\n",
      "loss_params.g_loss.lambda_asr.10.0\n",
      "loss_params.g_loss.lambda_f0.5.0\n",
      "loss_params.g_loss.lambda_f0_sty.0.1\n",
      "loss_params.g_loss.lambda_adv.2.0\n",
      "loss_params.g_loss.lambda_adv_cls.0.5\n",
      "loss_params.g_loss.norm_bias.0.5\n",
      "loss_params.d_loss.lambda_reg.1.0\n",
      "loss_params.d_loss.lambda_adv_cls.0.1\n",
      "loss_params.d_loss.lambda_con_reg.10.0\n",
      "loss_params.adv_cls_epoch.50\n",
      "loss_params.con_reg_epoch.30\n",
      "optimizer_params.lr.0.0001\n"
     ]
    }
   ],
   "source": [
    "def process_yaml(data, prefix=\"\"):\n",
    "    results = []\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            new_prefix = f\"{prefix}.{key}\" if prefix else key\n",
    "            results.extend(process_yaml(value, new_prefix))\n",
    "    elif isinstance(data, list):\n",
    "        for index, item in enumerate(data):\n",
    "            new_prefix = f\"{prefix}[{index}]\"\n",
    "            results.extend(process_yaml(item, new_prefix))\n",
    "    else:\n",
    "        results.append(f\"{prefix}.{data}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def read_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    processed_data = process_yaml(data)\n",
    "\n",
    "    for line in processed_data:\n",
    "        print(line)\n",
    "\n",
    "config_file = r\"C:\\Users\\Neesty\\PycharmProjects\\ml_sim_kc\\intern\\yaml_config\\example.yaml\"\n",
    "read_yaml_file(config_file)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}