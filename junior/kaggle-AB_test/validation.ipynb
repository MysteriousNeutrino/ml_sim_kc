{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split, RepeatedKFold\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, Union"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def prepare_dataset(DATA_PATH: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Prepare dataset.\n",
    "    Load data, split into X and y, one-hot encode categorical\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    DATA_PATH: str :\n",
    "        path to the dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray] :\n",
    "        X and y\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    df = df.drop([\"ID\"], axis=1)\n",
    "    y = df.pop(\"y\").values\n",
    "\n",
    "    # select only numeric columns\n",
    "    X_num = df.select_dtypes(include=\"number\")\n",
    "\n",
    "    # select only categorical columns and one-hot encode them\n",
    "    X_cat = df.select_dtypes(exclude=\"number\")\n",
    "    X_cat = pd.get_dummies(X_cat)\n",
    "\n",
    "    # combine numeric and categorical\n",
    "    X = pd.concat([X_num, X_cat], axis=1)\n",
    "    X = X.fillna(0).values\n",
    "\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "data_path = \"train.csv.zip\"\n",
    "X, y = prepare_dataset(data_path)\n",
    "params_list = [\n",
    "    {\"max_depth\": 10},  # baseline\n",
    "    {\"max_depth\": 2},\n",
    "    {\"max_depth\": 3},\n",
    "    # {\"max_depth\": 4},\n",
    "    # {\"max_depth\": 5},\n",
    "    # {\"max_depth\": 9},\n",
    "    # {\"max_depth\": 11},\n",
    "    {\"max_depth\": 12},\n",
    "    {\"max_depth\": 15},\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "from typing import Callable, Dict\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def cross_val_score(\n",
    "        model: Callable,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        cv: Union[int, Tuple[int, int]],\n",
    "        params_list: List[Dict],\n",
    "        scoring: Callable,\n",
    "        random_state: int = 42,\n",
    "        show_progress: bool = False,\n",
    ") -> np.ndarray:\n",
    "\n",
    "    if isinstance(cv, int):\n",
    "        kf = KFold(n_splits=cv,shuffle=True, random_state=random_state)\n",
    "    if isinstance(cv, tuple):\n",
    "        kf = RepeatedKFold(n_splits=cv[0], n_repeats=cv[1], random_state=random_state)\n",
    "    all_scores = []\n",
    "    for n,params in tqdm(enumerate(params_list)):\n",
    "        # fit\n",
    "        model.set_params(**params)\n",
    "        model_scores = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            model.fit(X_train, np.log1p(y_train))\n",
    "        # predict\n",
    "            y_pred = np.expm1(model.predict(X_test))\n",
    "        #evaluate\n",
    "            score = scoring(y_test, y_pred)\n",
    "            model_scores.append(score)\n",
    "        all_scores.append(model_scores)\n",
    "    return np.array(all_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "cv = (2,3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:27,  5.56s/it]\n",
      "5it [01:07, 13.42s/it]\n"
     ]
    }
   ],
   "source": [
    "all_scores_int = cross_val_score(RandomForestRegressor(n_estimators=100), X=X, y=y, cv=2, params_list=params_list, scoring=r2_score)\n",
    "all_scores_tuple = cross_val_score(RandomForestRegressor(n_estimators=100), X=X, y=y, cv=cv, params_list=params_list, scoring=r2_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.50494151, 0.59079276],\n       [0.44752522, 0.5645706 ],\n       [0.51910232, 0.60335357],\n       [0.50942104, 0.59089824],\n       [0.50139704, 0.5828795 ]])"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_int"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "all_scores_mean = []\n",
    "if isinstance(cv, tuple):\n",
    "    for j in range(cv[0]):\n",
    "        indixes = [i for i in(range(cv[0]*cv[1])) if i % cv[0] == j]\n",
    "        all_scores_mean.append(all_scores_tuple[:,indixes].mean(axis=1))\n",
    "    all_scores_mean = np.array(all_scores_mean).T\n",
    "if isinstance(cv, int):\n",
    "    all_scores_mean = all_scores.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "array([{'model_index': 2, 'avg_score': 0.5612279452414543, 'p_value': 0.038073349175414585, 'effect_sign': 1},\n       {'model_index': 3, 'avg_score': 0.5501596432684417, 'p_value': 0.48501209266135786, 'effect_sign': 0},\n       {'model_index': 4, 'avg_score': 0.542138266695591, 'p_value': 0.2319074847901385, 'effect_sign': 0},\n       {'model_index': 1, 'avg_score': 0.5060479103388542, 'p_value': 0.2272633372071376, 'effect_sign': 0}],\n      dtype=object)"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_list = []\n",
    "for i ,*(value) in enumerate(all_scores_mean[1:]):\n",
    "    mean = np.array(value).mean()\n",
    "    baseline_mean = np.array(all_scores_mean[0]).mean()\n",
    "    _, p_value = ttest_rel(all_scores_mean[0],*value)\n",
    "    compare_dict = {}\n",
    "    compare_dict['model_index'] = i+1\n",
    "    compare_dict['avg_score'] = mean\n",
    "    compare_dict['p_value'] = p_value\n",
    "    compare_dict['effect_sign'] = (1 if mean > baseline_mean else -1) if p_value < alpha else 0\n",
    "    compare_list.append(compare_dict)\n",
    "np.array(sorted(compare_list, key=lambda x: x['avg_score'], reverse=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.47740395, 0.52913998, 0.51648235, 0.51039212])"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_mean[1:].T[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "def cross_val_score(\n",
    "        model: Callable,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        cv: Union[int, Tuple[int, int]],\n",
    "        params_list: List[Dict],\n",
    "        scoring: Callable,\n",
    "        random_state: int = 42,\n",
    "        show_progress: bool = False,\n",
    ") -> np.ndarray:\n",
    "    if isinstance(cv, int):\n",
    "        kf = KFold(n_splits=cv,shuffle=True, random_state=random_state)\n",
    "    if isinstance(cv, tuple):\n",
    "        kf = RepeatedKFold(n_splits=cv[0], n_repeats=cv[1], random_state=random_state)\n",
    "    all_scores = []\n",
    "    for n,params in tqdm(enumerate(params_list)):\n",
    "        # fit\n",
    "        model.set_params(**params)\n",
    "        model_scores = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            model.fit(X_train, np.log1p(y_train))\n",
    "        # predict\n",
    "            y_pred = np.expm1(model.predict(X_test))\n",
    "        #evaluate\n",
    "            score = scoring(y_test, y_pred)\n",
    "            model_scores.append(score)\n",
    "        all_scores.append(model_scores)\n",
    "    return np.array(all_scores)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [05:37, 67.53s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.56186938, 0.43501315, 0.59687054, 0.6010241 , 0.58383614,\n        0.59509957, 0.58787666, 0.55886014, 0.47818819, 0.56496156],\n       [0.5097085 , 0.36850778, 0.52468815, 0.56239382, 0.54036264,\n        0.55695809, 0.49103926, 0.49110835, 0.41930866, 0.54316185],\n       [0.59384413, 0.43388222, 0.59811252, 0.61315444, 0.59782086,\n        0.61562857, 0.59820368, 0.55156666, 0.47808389, 0.57617157],\n       [0.57041839, 0.43773376, 0.59798818, 0.60519852, 0.5885233 ,\n        0.59665023, 0.59098726, 0.5610724 , 0.47965388, 0.56760145],\n       [0.54207877, 0.42317512, 0.5925958 , 0.59792945, 0.56566671,\n        0.57541082, 0.57806532, 0.54890585, 0.47080889, 0.55658331]])"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_int = cross_val_score(RandomForestRegressor(n_estimators=200), X=X, y=y, cv=(5,2), params_list=params_list, scoring=r2_score)\n",
    "all_scores_int"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "data": {
      "text/plain": "TtestResult(statistic=-8.196244152122365, pvalue=1.822908207065538e-05, df=9)"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(all_scores_int[1], all_scores_int[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "all_scores_mean = []\n",
    "if isinstance(cv, tuple):\n",
    "    for j in range(cv[0]):\n",
    "        indixes = [i for i in(range(cv[0]*cv[1])) if i % cv[0] == j]\n",
    "        all_scores_mean.append(all_scores_tuple[:,indixes].mean(axis=1))\n",
    "    all_scores_mean = np.array(all_scores_mean).T\n",
    "if isinstance(cv, int):\n",
    "    all_scores_mean = all_scores_int.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.53252316, 0.55498465],\n       [0.48676735, 0.52533034],\n       [0.5500064 , 0.57208828],\n       [0.53420665, 0.55909289],\n       [0.52444872, 0.54999557]])"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "data": {
      "text/plain": "TtestResult(statistic=-4.683422601298516, pvalue=0.1339194777047209, df=1)"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(all_scores_mean[1], all_scores_mean[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "data": {
      "text/plain": "array([{'model_index': 2, 'avg_score': 0.5656468536180654, 'p_value': 0.032221027784356475, 'effect_sign': 1},\n       {'model_index': 3, 'avg_score': 0.5595827369756207, 'p_value': 0.001213844801917392, 'effect_sign': 1},\n       {'model_index': 4, 'avg_score': 0.5451220040078354, 'p_value': 0.0002502157698045562, 'effect_sign': -1},\n       {'model_index': 1, 'avg_score': 0.5007237089877614, 'p_value': 1.822908207065538e-05, 'effect_sign': -1}],\n      dtype=object)"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha= 0.05\n",
    "compare_list = []\n",
    "for i ,*(value) in enumerate(all_scores_int[1:]):\n",
    "    mean = np.array(value).mean()\n",
    "    baseline_mean = np.array(all_scores_int[0]).mean()\n",
    "    _, p_value = ttest_rel(all_scores_int[0],*value)\n",
    "    compare_dict = {}\n",
    "    compare_dict['model_index'] = i+1\n",
    "    compare_dict['avg_score'] = mean\n",
    "    compare_dict['p_value'] = p_value\n",
    "    compare_dict['effect_sign'] = (1 if mean > baseline_mean else -1) if p_value < alpha else 0\n",
    "    compare_list.append(compare_dict)\n",
    "np.array(sorted(compare_list, key=lambda x: x['avg_score'], reverse=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5563599429372117"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores_int[0].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}